import streamlit as st
import pandas as pd
from src.utils import load_config, get_credentials
from src.crawler import TradeDataCrawler
from src.preprocessor import DataPreprocessor

def main():
    st.set_page_config(page_title="Trade Crawler Pro", layout="wide")
    st.title("Tool Crawl Data - Auto Split Files")

    config = load_config()
    creds = get_credentials()

    # --- INPUT UI ---
    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input("T·ª´ ng√†y").strftime("%Y-%m-%d")
        company_name = st.text_input("T√™n c√¥ng ty / T·ª´ kh√≥a")
    with col2:
        end_date = st.date_input("ƒê·∫øn ng√†y").strftime("%Y-%m-%d")
        hs_code = st.text_input("HS Code")

    if st.button("üöÄ B·∫Øt ƒë·∫ßu Crawl"):
        crawler = TradeDataCrawler(config, creds)
        processor = DataPreprocessor(config)

        if not crawler.login():
            st.error("ƒêƒÉng nh·∫≠p th·∫•t b·∫°i!")
            return

        # UI Components
        status_box = st.empty()
        result_area = st.container()
        
        # --- C·∫§U H√åNH BATCH ---
        # L·∫•y gi·ªõi h·∫°n d√≤ng m·ªói file t·ª´ config. M·∫∑c ƒë·ªãnh 50,000 d√≤ng.
        MAX_ROWS_PER_FILE = config['processing'].get('max_rows_per_file', 50000)
        
        buffer = []          # C√°i x√¥ ch·ª©a d·ªØ li·ªáu t·∫°m
        file_results = []    # Danh s√°ch c√°c file ƒë√£ t·∫°o xong
        total_fetched = 0    # T·ªïng s·ªë d√≤ng ƒë√£ crawl ƒë∆∞·ª£c t·ª´ ƒë·∫ßu
        part_index = 1       # ƒê·∫øm s·ªë th·ª© t·ª± file (part_1, part_2...)

        # G·ªçi h√†m Generator (Streaming)
        data_gen = crawler.fetch_data_generator(start_date, end_date, company_name, hs_code)

        try:
            # V√≤ng l·∫∑p l·∫•y t·ª´ng trang data v·ªÅ
            for page_data in data_gen:
                if not page_data: 
                    continue

                # 1. ƒê·ªï data v√†o x√¥
                buffer.extend(page_data)
                total_fetched += len(page_data)

                # Hi·ªÉn th·ªã tr·∫°ng th√°i realtime
                status_box.info(
                    f"üîÑ ƒêang crawl... T·ªïng: **{total_fetched}** d√≤ng. "
                    f"ƒêang ch·ªù ƒë√≥ng g√≥i: **{len(buffer)}/{MAX_ROWS_PER_FILE}** d√≤ng (File Part {part_index})"
                )

                # 2. Ki·ªÉm tra: N·∫øu x√¥ ƒë·∫ßy tr√†n -> C·∫Øt ra l√†m file
                while len(buffer) >= MAX_ROWS_PER_FILE:
                    # C·∫Øt ƒë√∫ng s·ªë l∆∞·ª£ng quy ƒë·ªãnh
                    chunk_to_save = buffer[:MAX_ROWS_PER_FILE]
                    
                    # Ph·∫ßn d∆∞ gi·ªØ l·∫°i trong x√¥ cho ƒë·ª£t sau
                    buffer = buffer[MAX_ROWS_PER_FILE:] 
                    
                    # T·∫°o file Excel
                    file_name = f"trade_data_part_{part_index}.xlsx"
                    status_box.warning(f"üíæ ƒêang t·∫°o file **{file_name}**...")
                    
                    excel_bytes = processor.create_excel_bytes(pd.DataFrame(chunk_to_save))
                    
                    if excel_bytes:
                        file_results.append({'name': file_name, 'data': excel_bytes})
                        part_index += 1 # TƒÉng s·ªë th·ª© t·ª± file ti·∫øp theo

            # 3. X·ª¨ L√ù PH·∫¶N C√íN L·∫†I (LEFTOVER)
            # Sau khi crawl xong h·∫øt, n·∫øu trong x√¥ v·∫´n c√≤n √≠t d·ªØ li·ªáu ch∆∞a ƒë·ªß 50k
            if buffer:
                file_name = f"trade_data_part_{part_index}.xlsx"
                status_box.warning(f"üíæ ƒêang t·∫°o file cu·ªëi c√πng **{file_name}**...")
                excel_bytes = processor.create_excel_bytes(pd.DataFrame(buffer))
                if excel_bytes:
                    file_results.append({'name': file_name, 'data': excel_bytes})

            # --- K·∫æT TH√öC ---
            status_box.success(f"‚úÖ Ho√†n th√†nh! T·ªïng c·ªông: {total_fetched} d√≤ng. ƒê√£ chia th√†nh {len(file_results)} file.")

            # Hi·ªÉn th·ªã n√∫t download
            st.write("### üìÇ Danh s√°ch file t·∫£i xu·ªëng:")
            
            # Chia c·ªôt hi·ªÉn th·ªã cho ƒë·∫πp
            cols = st.columns(3)
            for i, f in enumerate(file_results):
                with cols[i % 3]:
                    st.download_button(
                        label=f"üì• T·∫£i {f['name']}",
                        data=f['data'],
                        file_name=f['name'],
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"dl_{i}"
                    )

        except Exception as e:
            st.error(f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")

if __name__ == "__main__":
    main()